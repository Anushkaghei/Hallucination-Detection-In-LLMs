{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anushkaghei/Hallucination-Detection-In-LLMs/blob/main/Stepback_Prompting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8b4b491-76da-4650-96c5-3008914bea5b",
      "metadata": {
        "id": "a8b4b491-76da-4650-96c5-3008914bea5b"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate, FewShotChatMessagePromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from langchain_openai import ChatOpenAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d43ba461-776c-4072-bdf4-7a1b7d47615b",
      "metadata": {
        "id": "d43ba461-776c-4072-bdf4-7a1b7d47615b"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52f80cb8-98b5-473b-bb3d-9d0b89ecdb3f",
      "metadata": {
        "id": "52f80cb8-98b5-473b-bb3d-9d0b89ecdb3f"
      },
      "outputs": [],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your model and tokenizer\n",
        "model_name = \"deepset/roberta-base-squad2\"\n",
        "nlp = pipeline('question-answering', model=model_name, tokenizer=model_name)\n",
        "\n",
        "# Function to split questions and contexts\n",
        "def split_questions_contexts(csv_file):\n",
        "    questions_contexts = []\n",
        "    with open(csv_file, 'r', encoding='utf-8') as file:\n",
        "        reader = csv.reader(file)\n",
        "        for row in reader:\n",
        "            context = \" \".join(row[:-1])\n",
        "            for question in row:\n",
        "                if question.endswith(\"?\"):\n",
        "                    questions_contexts.append({'question': question, 'context': context})\n",
        "    return questions_contexts\n",
        "\n",
        "# Example usage\n",
        "csv_file = 'dataset1.csv'  # Change to your CSV file path\n",
        "questions_contexts = split_questions_contexts(csv_file)\n",
        "\n",
        "# Get predictions for each question-context pair\n",
        "for qa_input in questions_contexts:\n",
        "    try:\n",
        "        res = nlp(qa_input)\n",
        "        print(\"Question:\", qa_input['question'])\n",
        "        print(\"Context:\", qa_input['context'])\n",
        "        print(\"Answer:\", res['answer'])\n",
        "        print()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing input: {qa_input}\")\n",
        "        print(f\"Error message: {str(e)}\")\n",
        "        print(\"Skipping to next input.\")\n",
        "        continue\n"
      ],
      "metadata": {
        "id": "g4lRLz6CGJVx"
      },
      "id": "g4lRLz6CGJVx",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}